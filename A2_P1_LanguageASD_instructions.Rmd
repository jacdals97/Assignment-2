---
title: "Assignment 2 - Language Development in ASD - Part 1 - Explaining development"
author: "Study group 12"
date: "09-10-2019"
output: 
  md_document: 
    variant: markdown_github
---
    
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Assignment 2

In this assignment you will have to discuss a few important questions (given the data you have). More details below. The assignment submitted to the teachers consists of:
- a report answering and discussing the questions (so we can assess your conceptual understanding and ability to explain and critically reflect)
- a link to a git repository with all the code (so we can assess your code)

Part 1 - Basic description of language development
- Describe your sample (n, age, gender, clinical and cognitive features of the two groups) and critically assess whether the groups (ASD and TD) are balanced
- Describe linguistic development (in terms of MLU over time) in TD and ASD children (as a function of group). 
- Describe how parental use of language (in terms of MLU) changes over time. What do you think is going on?
- Include individual differences in your model of language development (in children). Identify the best model.

Part 2 - Model comparison
- Discuss the differences in performance of your model in training and testing data
- Which individual differences should be included in a model that maximizes your ability to explain/predict new data?
- Predict a new kid's performance (Bernie) and discuss it against expected performance of the two groups

Part 3 - Simulations to plan a new study
- Report and discuss a power analyses identifying how many new kids you would need to replicate the results

The following involves only Part 1.

## Learning objectives

- Summarize and report data and models
- Critically apply mixed effects (or multilevel) models
- Explore the issues involved in feature selection


# Quick recap
Autism Spectrum Disorder is often related to language impairment. However, this phenomenon has not been empirically traced in detail:
i) relying on actual naturalistic language production,  ii) over extended periods of time.

We therefore videotaped circa 30 kids with ASD and circa 30 comparison kids (matched by linguistic performance at visit 1) for ca. 30 minutes of naturalistic interactions with a parent. We repeated the data collection 6 times per kid, with 4 months between each visit. We transcribed the data and counted: 
i) the amount of words that each kid uses in each video. Same for the parent.
ii) the amount of unique words that each kid uses in each video. Same for the parent.
iii) the amount of morphemes per utterance (Mean Length of Utterance) displayed by each child in each video. Same for the parent. 

This data is in the file you prepared in the previous class. 

NB. A few children have been excluded from your datasets. We will be using them next week to evaluate how good your models are in assessing the linguistic development in new participants.

This RMarkdown file includes 
1) questions (see above). Questions have to be answered/discussed in a separate document that you have to directly send to the teachers.
2) A break down of the questions into a guided template full of hints for writing the code to solve the exercises. Fill in the code and the paragraphs as required. Then report your results in the doc for the teachers.

REMEMBER that you will have to have a github repository for the code and send the answers to Kenneth and Riccardo without code (but a link to your github/gitlab repository). This way we can check your code, but you are also forced to figure out how to report your analyses :-)

Before we get going, here is a reminder of the issues you will have to discuss in your report:

1- Describe your sample (n, age, gender, clinical and cognitive features of the two groups) and critically assess whether the groups (ASD and TD) are balanced
2- Describe linguistic development (in terms of MLU over time) in TD and ASD children (as a function of group). 
3- Describe how parental use of language (in terms of MLU) changes over time. What do you think is going on?
4- Include individual differences in your model of language development (in children). Identify the best model.

# Let's go

### Loading the relevant libraries

Load necessary libraries : what will you need?
- e.g. something to deal with the data
- e.g. mixed effects models
- e.g. something to plot with

```{r Load Libraries, include = FALSE}
library(pacman)
p_load(tidyverse, ggplot2, pastecs, reshape, lme4, MuMIn, mctest)

options(na.action = "na.fail")
```

### Define your working directory and load the data
If you created a project for this class and opened this Rmd file from within that project, your working directory is your project directory.

If you opened this Rmd file outside of a project, you will need some code to find the data:
- Create a new variable called locpath (localpath)
- Set it to be equal to your working directory
- Move to that directory (setwd(locpath))
- Load the data you saved last time (use read_csv(fileName))

```{r Load Data, include = FALSE}
clean <- read.csv("AutismClean.csv")
```

### Characterize the participants (Exercise 1)

Identify relevant variables: participants demographic characteristics, diagnosis, ADOS, Verbal IQ, Non Verbal IQ, Socialization, Visit, Number of words used, Number of unique words used, mean length of utterance in both child and parents.

Make sure the variables are in the right format.

Describe the characteristics of the two groups of participants and whether the two groups are well matched.

```{r descriptive stats, include = T}
clean %>% subset(VISIT == 1) %>% group_by(Diagnosis, Gender) %>% summarise(Agem = mean(Age), n()) #checking age, diagnosis and gender balances 

clean %>% subset(VISIT == 1) %>% group_by(Diagnosis, Ethnicity) %>% summarise(n()) #checking ethnicity balance

clean %>% subset(VISIT == 1) %>% group_by(Diagnosis) %>% summarise(mean(MOT_MLU), mean(CHI_MLU), mean(MullenRawv1), mean(ExpressiveLangRawv1), mean(Socialization), mean(ADOSv1), mean(tokens_CHI), mean(types_CHI)) #MChecking differences of preictors between the ASd and TD kids



```




## Let's test hypothesis 1: Children with ASD display a language impairment  (Exercise 2)

### Hypothesis: The child's MLU changes: i) over time, ii) according to diagnosis

Let's start with a simple mixed effects linear model

Remember to plot the data first and then to run a statistical test.
- Which variable(s) should be included as fixed factors?
- Which variable(s) should be included as random factors?

```{r, include=TRUE}

clean$VISIT <- as.numeric(clean$VISIT)
clean$SUBJ <- as.factor(clean$SUBJ)

#Plotting the effect of visit on CHI_MLU across diagnosis using bar plot 
ggplot(clean, aes(VISIT, CHI_MLU, fill = Diagnosis))+
  geom_bar(stat = "summary", position = "dodge")+
  geom_errorbar(stat = "summary", position = position_dodge(width = 0.9))


#Plotting the linear relationship between visit and CHI_MLU across diagnosis
ggplot(clean, aes(VISIT, CHI_MLU, colour = Diagnosis))+
  geom_point()+
  geom_smooth(method = "lm", alpha = 0)

#Highlightinh individual differences between children in the two conditions
ggplot(clean, aes(VISIT, CHI_MLU, color = SUBJ))+
  facet_wrap(.~Diagnosis)+
  geom_smooth(method = lm, alpha = 0)


#Creating base model in which child MLU is predicted by the fixed effect of the interaction between visit and diagnosis. 
#The model is both a random intercept and random slope model. Each participant has been assigned their own intercept and are allowed the vary independently
model1 <- lmer(CHI_MLU ~ VISIT*Diagnosis + (1+VISIT|SUBJ), clean, REML = FALSE)
summary(model1)


#Creating null model
model0 <- lmer(CHI_MLU ~ 1 + (1+VISIT|SUBJ), clean, REML = FALSE)
summary(model0)

```


Convergence troubleshoot
```{r, include=TRUE}

tt <- getME(model1,"theta")
ll <- getME(model1,"lower")
min(tt[ll==0]) #output should be more than 10^-6

#using package numDeriv to calculate gradients
derivs1 <- model1@optinfo$derivs
sc_grad1 <- with(derivs1,solve(Hessian,gradient))
max(abs(sc_grad1))

#restarting from last fit
ss <- getME(model1,c("theta","fixef"))
m2 <- update(model1,start=ss,control=lmerControl(optCtrl=list(maxfun=2e4)))


```




How would you evaluate whether the model is a good model?

```{r, include=TRUE}


#Comparing null model and model 1
anova(model0, model1)

#Computing marginal and conditional R-squared for null model
r.squaredGLMM(model0)

#Computing marginal and conditional R-squared for model 1
r.squaredGLMM(model1)

#adding fitted values to data frame
clean$fit <- fitted.values(model1)

#Plotting fitted values against actual values
ggplot(clean, aes(fit, CHI_MLU))+
  geom_point()+
  labs(x = "Predicted values", y = "Child MLU")



```

Not too good, right? Let's check whether a growth curve model is better.
Remember: a growth curve model assesses whether changes in time can be described by linear, or quadratic, or cubic (or... etc.) components.
First build the different models, then compare them to see which one is better.

```{r ex2 growth curve,}

#Has been excluded


```

Exciting right? Let's check whether the model is doing an alright job at fitting the data. Plot the actual CHI_MLU data against the predictions of the model fitted(model). 

```{r}



```

Now it's time to report our results.
Remember to report:
- the estimates for each predictor (beta estimate, standard error, p-value)
- A plain word description of the results
- A plot of your model's predictions (and some comments on whether the predictions are sensible)

[REPORT THE RESULTS]
Linguistic development of children MLU is affected by ... [COMPLETE]

## Let's test hypothesis 2: Parents speak equally to children with ASD and TD  (Exercise 3)

### Hypothesis: Parental MLU changes: i) over time, ii) according to diagnosis

```{r, include=TRUE}

#MOT_MLU model, MOT_MLU predicted by the fixed effect of the interaction between visit and diagnosis. 
#The model is both a random intercept and random slope model. Each participant has been assigned their own intercept and are allowed the vary independently 
MOTmodel1 <- lmer(MOT_MLU ~ VISIT*Diagnosis + (1+VISIT|SUBJ), clean, REML = T)
summary(MOTmodel1)

#Creating null model
MOTmodel0 <- lmer(MOT_MLU ~ 1 + (1+VISIT|SUBJ), clean, REML = T, control = lmerControl())
summary(MOTmodel0)

#Comparing models using anova
anova(MOTmodel0, MOTmodel1)

#Plotting the linear relationship between visit and MOT_MLU across diagnosis
ggplot(clean, aes(VISIT, MOT_MLU, colour = Diagnosis))+
  geom_point()+
  geom_smooth(method = "lm", alpha = 0)
```


### Adding new variables (Exercise 4)

Your task now is to figure out how to best describe the children linguistic trajectory. The dataset contains a bunch of additional demographic, cognitive and clinical variables (e.g.verbal and non-verbal IQ). Try them out and identify the statistical models that best describes your data (that is, the children's MLU). Describe how you selected the best model and send the code to run the model to Riccardo and Kenneth


```{r, include=TRUE}

#Very very naughty data exploration using the dredge tool

#Specifying complex model
chi_model1 <- lmer(CHI_MLU ~ VISIT*Diagnosis*MOT_MLU*ExpressiveLangRawv1 + (1+VISIT|SUBJ), clean, REML =F, control=lmerControl(optimizer="bobyqa",
                            optCtrl=list(maxfun=2e5)))

summary(chi_model1)
search2 <- dredge(chi_model1) #using dredge to select model with lowest AICc
subset(search2, delta == 0)



#Specifying the dredged model
dredge_model <- lmer(CHI_MLU ~ VISIT*Diagnosis*ExpressiveLangRawv1 + MOT_MLU + ExpressiveLangRawv1:MOT_MLU + (1+VISIT|SUBJ), clean, REML =F) 
summary(dredge_model)
anova(dredge_model)
r.squaredGLMM((dredge_model))


#This is the model we ended up with in the end. We found it by specifying a lot of different models and using anova to test which model was better.
own_model <- lmer(CHI_MLU ~ VISIT*Diagnosis + ExpressiveLangRawv1 + MOT_MLU + (1+VISIT|SUBJ), clean, REML =F) 
summary(own_model)
anova(own_model)
r.squaredGLMM((own_model))


#Using the anova function, models are compared in increasing order of complexity 
anova(own_model, dredge_model)
#dredge model gives a smaller AIC and BIC but we stick with the other model as it is easier to interpret and because we found it in a less malicious way.
```




How you could choose which predictors to include

The forbidden interval - (lasso/elasticnet)
sum up the beta estimates
divide each betaestimate with the sum
if the values are between 1 and -1 then drop that predictor-estimate